{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5953c8-c746-4ffa-85cc-243b3708e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import do_cv_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8ffca-69a8-45a5-8e61-8dfba36dbf8d",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Nesta aula vamos usar a SVM (*Support Vector Machine*) como algoritmo de classificação e comparar seu desempenho com o KNN. O objetivo deste caderno em relação a SVM é mostrar como usar a SVM como um classificador \"caixa-preta\". O treinamento da SVM é um procedimento computacionalmente complexo, que está fora do escopo desta disciplina.\n",
    "\n",
    "Dadas instâncias com $n$ atributos, a SVM encontra um classificador linear de margem máxima suave que separa 2 classes em uma dimensionalidade $m$, tal que $m>n$. A projeção dos dados do espaço $n$-dimensional para um espaço $m$ dimensional onde acontece por meio de transformações não-lineares descritas por *kernels*. A idéia é que esta projeção torne um problema de classificação não-linear em um problema linearmente separável por um hiperplano com $m-1$ dimensões. A otimização do melhor hiperplano é feito com base nos pontos (instâncias) que determinam a margem suave. Estes pontos são conhecidos como **vetores de suporte**, do inglês *support vectors*.\n",
    "\n",
    "Para ter uma idéia mais intuitiva sobre como a SVM funciona, consulte o material a seguir:\n",
    "\n",
    "* [Support Vector Machines Part 1 (of 3): Main Ideas!!!](https://www.youtube.com/watch?v=efR1C6CvhmE)\n",
    "* [Support Vector Machines Part 2: The Polynomial Kernel (Part 2 of 3)](https://www.youtube.com/watch?v=Toet3EiSFcM)\n",
    "* [Support Vector Machines Part 3: The Radial (RBF) Kernel (Part 3 of 3)](https://www.youtube.com/watch?v=Qc5IyLW_hns)\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "Hoje vamos usar a base de dados *heart*. Esta base de dados contém informações clínicas e resultados de exames laboratoriais de pacientes cardíacos. O atributo de saída indica se o paciente morreu devido a algum problema cardíaco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b74202-f3f8-4526-8494-05e2dcabf12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_50</th>\n",
       "      <th>MD_50</th>\n",
       "      <th>SBP_50</th>\n",
       "      <th>DBP_50</th>\n",
       "      <th>HT_50</th>\n",
       "      <th>WT_50</th>\n",
       "      <th>CHOL_50</th>\n",
       "      <th>SES</th>\n",
       "      <th>CL_STATUS</th>\n",
       "      <th>MD_62</th>\n",
       "      <th>SBP_62</th>\n",
       "      <th>DBP_62</th>\n",
       "      <th>CHOL_62</th>\n",
       "      <th>WT_62</th>\n",
       "      <th>IHD_DX</th>\n",
       "      <th>DEATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>147</td>\n",
       "      <td>291</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>78</td>\n",
       "      <td>271</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>167</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>68</td>\n",
       "      <td>250</td>\n",
       "      <td>165</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>222</td>\n",
       "      <td>342</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>90</td>\n",
       "      <td>304</td>\n",
       "      <td>223</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>229</td>\n",
       "      <td>239</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>209</td>\n",
       "      <td>227</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>134</td>\n",
       "      <td>243</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "      <td>261</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>148</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>65</td>\n",
       "      <td>273</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>137</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>76</td>\n",
       "      <td>198</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>150</td>\n",
       "      <td>210</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>84</td>\n",
       "      <td>66</td>\n",
       "      <td>138</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>88</td>\n",
       "      <td>160</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>157</td>\n",
       "      <td>260</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>251</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE_50  MD_50  SBP_50  DBP_50  HT_50  WT_50  CHOL_50  SES  CL_STATUS  \\\n",
       "0        42      1     110      65     64    147      291    2          8   \n",
       "1        53      1     130      72     69    167      278    1          6   \n",
       "2        53      2     120      90     70    222      342    4          8   \n",
       "3        48      4     120      80     72    229      239    4          8   \n",
       "4        53      3     118      74     66    134      243    3          8   \n",
       "..      ...    ...     ...     ...    ...    ...      ...  ...        ...   \n",
       "195      50      1     115      80     66    148      300    2          8   \n",
       "196      23      1     110      70     69    137      120    3          8   \n",
       "197      20      3     130      80     66    150      210    5          0   \n",
       "198      46      3     140      84     66    138      130    4          6   \n",
       "199      36      1     100      70     70    157      260    3          8   \n",
       "\n",
       "     MD_62  SBP_62  DBP_62  CHOL_62  WT_62  IHD_DX  DEATH  \n",
       "0        4     120      78      271    146       2      1  \n",
       "1        2     122      68      250    165       9      1  \n",
       "2        1     132      90      304    223       2      1  \n",
       "3        2     118      68      209    227       3      1  \n",
       "4        5     118      56      261    138       2      1  \n",
       "..     ...     ...     ...      ...    ...     ...    ...  \n",
       "195      1     115      65      273    152       0      0  \n",
       "196      2     112      76      198    153       0      0  \n",
       "197      1     130      85      274    158       0      0  \n",
       "198      2     148      88      160    157       0      0  \n",
       "199      3     120      86      251    152       0      0  \n",
       "\n",
       "[200 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca2c30d-b4d8-4614-828f-bebfaed476b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando se há dados faltantes\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aee2c38-3e90-4f50-ba7c-d97e7823fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atributo de saída\n",
    "y = df['DEATH'].values.ravel()\n",
    "\n",
    "#Atributos de entrada\n",
    "X = df.drop('DEATH', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce54416-8378-4fb3-87ef-6163cb44a0ed",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde8a446-7dad-4641-996d-f7c7dcdf6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7712f128107461b9182b3acf6d2def6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds avaliados:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Avaliar o desempenho do KNN nesta base de dados usando validação cruzada. \n",
    "#Para cada fold, realiza uma busca exaustiva para escolher o melhor $k$.\n",
    "accs_knn = do_cv_knn(X.values, y, 10, range(1, 20, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3765675-db99-4e23-941a-bbaee7b5e731",
   "metadata": {},
   "source": [
    "Está na hora de criar uma função para calcular as estatísticas das acurácias obtidas na validação cruzada. Também já vamos implementar uma função para imprimir estas estatísticas de forma adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d7ba16-bc69-4689-aa8e-af59eddf94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_estatisticas(resultados):\n",
    "    return np.mean(resultados), np.std(resultados), np.min(resultados), np.max(resultados)\n",
    "\n",
    "def imprimir_estatisticas(resultados):\n",
    "    media, desvio, mini, maxi = calcular_estatisticas(resultados)\n",
    "    print(\"Resultados: %.2f +- %.2f, min: %.2f, max: %.2f\" % (media, desvio, mini, maxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ed1e4e-5a90-47a7-8214-def3ef1307ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: 0.69 +- 0.06, min: 0.60, max: 0.80\n"
     ]
    }
   ],
   "source": [
    "imprimir_estatisticas(accs_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383528c-2027-48d4-802d-ca84e216e8aa",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "A biblioteca *sklearn* utiliza uma implementação famosa da SVM chamada de libSVM. Esta implementação está no módulo ``sklearn.svm``. Neste módulo, a classe ``SVC`` implementa a SVM configurável, que já vem com vários *kernels* implementados. Na aula de hoje vamos usar o kernel *rbf* (*radial basis function*), que é comumente utilizado. Outros kernels bastante usados são os kernels *linear* e *poly*.\n",
    "\n",
    "Dependendo do *kernel* escolhido, há diferentes hiperparâmetros que precisam ser otimizados.\n",
    "\n",
    "O kernel *rbf* possui um parâmetro $\\gamma$ (gamma) que controla a influência da distância entre os pontos no cálculo da margem suave. Este parâmetro deve ser otimizado para obter os melhores resultados. É usual fazer uma busca exaustiva usando validação cruzada para otimizar este parâmetro. Os valores comumente avaliados são: $1/(\\text{n_atributos} * \\text{var}(X) )$ (``scale`` no sklearn), $1/\\text{n_atributos}$ (``auto`` no sklearn), $2\\times10^{-2}$, $2\\times10^{-3}$, $2\\times10^{-4}$ e $2\\times10^{-5}$.\n",
    "\n",
    "Outro parâmetro importante é a largura da margem suave, comumente especificado como $C$. É usual fazer uma busca exaustiva usando validação cruzada para otimizar este parâmetro. Os valores comumente avaliados são: $1$, $10$, $100$, $1000$ e $10000$.\n",
    "\n",
    "A função ``selecionar_melhor_svm`` faz uma busca exaustiva pela melhor combinação de $C$ e $\\gamma$ usando um conjunto de validação. O procedimento pode ser facilmente alterado para usar validação cruzada para fazer esta busca (usando ``GridSearchCV``).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d37a8e-7cc1-4fc1-8918-991a7495643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97c5733-d448-4c2a-8d9c-bcb1f62320b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cs e gammas são listas com os valores a serem avaliados para os respectivos parâmetros.\n",
    "def selecionar_melhor_svm(Cs, gammas, X_treino : np.ndarray, X_val : np.ndarray, \n",
    "                          y_treino : np.ndarray, y_val : np.ndarray, n_jobs=4):\n",
    "    \n",
    "    def treinar_svm(C, gamma, X_treino, X_val, y_treino, y_val):\n",
    "        svm = SVC(C=C, gamma=gamma)\n",
    "        svm.fit(X_treino, y_treino)\n",
    "        pred = svm.predict(X_val)\n",
    "        return accuracy_score(y_val, pred)\n",
    "    \n",
    "    #gera todas as combinações de parametros C e gamma, de acordo com as listas de valores recebidas por parametro.\n",
    "    #Na prática faz o produto cartesiano entre Cs e gammas.\n",
    "    combinacoes_parametros = list(itertools.product(Cs, gammas))\n",
    "    \n",
    "    #Treinar modelos com todas as combinações de C e gamma\n",
    "    acuracias_val = Parallel(n_jobs=n_jobs)(delayed(treinar_svm)\n",
    "                                       (c, g, X_treino, X_val, y_treino, y_val) for c, g in combinacoes_parametros)       \n",
    "    \n",
    "    melhor_val = max(acuracias_val)\n",
    "    #Encontrar a combinação que levou ao melhor resultado no conjunto de validação\n",
    "    melhor_comb = combinacoes_parametros[np.argmax(acuracias_val)]   \n",
    "    melhor_c = melhor_comb[0]\n",
    "    melhor_gamma = melhor_comb[1]\n",
    "    \n",
    "    #Treinar uma SVM com todos os dados de treino e validação usando a melhor combinação de C e gamma.\n",
    "    svm = SVC(C=melhor_c, gamma=melhor_gamma)\n",
    "    svm.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "\n",
    "    return svm, melhor_comb, melhor_val\n",
    "\n",
    "#Implementa a validação cruzada para avaliar o desempenho da SVM na base de dados com as instâncias X e as saídas y.\n",
    "#cv_splits indica o número de partições que devem ser criadas.\n",
    "#Cs é a lista com os valores C que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "#gammas s é a lista com os valores gamma que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "def do_cv_svm(X, y, cv_splits, Cs=[1], gammas=['scale']):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "    \n",
    "    pgb = tqdm(total=cv_splits, desc='Folds avaliados')\n",
    "    \n",
    "    for treino_idx, teste_idx in skf.split(X, y):\n",
    "\n",
    "        X_treino = X[treino_idx]\n",
    "        y_treino = y[treino_idx]\n",
    "\n",
    "        X_teste = X[teste_idx]\n",
    "        y_teste = y[teste_idx]\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, stratify=y_treino, test_size=0.2, random_state=1)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        X_val = ss.transform(X_val)\n",
    "\n",
    "        svm, _, _ = selecionar_melhor_svm(Cs, gammas, X_treino, X_val, y_treino, y_val)\n",
    "        pred = svm.predict(X_teste)\n",
    "\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "        \n",
    "        pgb.update(1)\n",
    "        \n",
    "    pgb.close()\n",
    "    \n",
    "    return acuracias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bed179-32a1-417a-ba67-d73fb5a801b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85990f17b9824c418880a9a994028307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds avaliados:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs_svm = do_cv_svm(X.values, y, 10, Cs=[1, 10, 100, 1000], gammas=['scale', 'auto', 2e-2, 2e-3, 2e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1470763-a9c8-4904-9960-458f711aefd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: 0.69 +- 0.06, min: 0.60, max: 0.80\n"
     ]
    }
   ],
   "source": [
    "imprimir_estatisticas(accs_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2c7fe5-f29e-4186-9749-b7de5265a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: 0.71 +- 0.05, min: 0.65, max: 0.80\n"
     ]
    }
   ],
   "source": [
    "imprimir_estatisticas(accs_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed9a90-253a-4920-9d16-b902b9365564",
   "metadata": {},
   "source": [
    "# Teste de Hipótese Nula pelo Teste t de Student\n",
    "\n",
    "A acurácia com KNN foi $0.69\\pm0.06$, enquanto a acurácia com a SVM foi de $0.71\\pm0.05$. Considerando apenas a diferença na média, o resultado com a SVM parece ter sido superior ao resultado com KNN. Entretanto, note que os desvios-padrão dos dois resultados são relativamente altos. Por exemplo, podemos esperar que, para dados desconhecidos, a acurácia do KNN seja entre $0.63$ e $0.75$. Já para a SVM esperamos que a acurácia seja entre $0.66$ e $0.76$. Veja que há uma sobreposição grande de acurácias prováveis entre KNN e SVM. \n",
    "\n",
    "Assim, a pergunta central aqui é: a diferença entre as médias dos resultados obtidos pelo KNN e pela SVM é **estatisticamente significativa?** Para responder esta pergunta, existem os testes de hipótese estatísticos. Na terminologia estatística, quando queremos verificar se duas distribuições estatísticas (por exemplo a distribuição gaussiana que estamos assumindo ao representar os testes usando a média e o desvio-padrão) são diferentes, perguntamos se é possível rejeitar a **hipótese nula**. A hipótese nula é a hipótese que diz que não há diferença significativa entre as duas distribuições.\n",
    "\n",
    "O teste t de Student pode ser usado para verificar se é possível rejeitar a hipótese nula quando estamos comparando a diferença na média de duas distribuições estatísticas. O teste é realizado em duas etapas:\n",
    "\n",
    "1. Calcular o p-valor ($p$) da diferença entre as médias usando a estatística t;\n",
    "2. Se $p \\leq \\alpha$, podemos rejeitar a hipótese nula. Ao rejeitar a hipótese nula estamos dizendo que a diferença entre as médias é estatisticamente significativa.\n",
    "3. Caso o $p > \\alpha$, não é possível rejeitar a hipótese nula. Desta forma, não é possível afirmar que a diferença entre as médias é estatisticamente significativa.\n",
    "\n",
    "Como interpretar o valor de $p$? $p$ é um número entre 0 e 1 que indica a probabilidade que a diferença nas médias seja resultado de um efeito aleatório, ou seja, algo não-relacionado com o que está sendo comparado. Por exemplo, se ao comparar o desempenho os dois classificadores acima obtermos $p=0.1$, isto indicaria que há 10% de chance que a diferença nas médias obtidas com KNN e SVM seja oriunda do particionamento utilizado para o treino e teste. Ou seja, é mais provável que as diferenças obtidas sejam oriundas das diferenças no funcionamento dos algoritmos KNN e SVM.\n",
    "\n",
    "Em outras palavras, quanto mais próximo $p$ estiver de 0, mais confiantes estamos que a diferença na média é significativa. Resta a pergunta: como escolher o valor para $\\alpha$?\n",
    "\n",
    "Um valor comumente utilizado para comparar modelos estatísticos na área de aprendizagem de máquina (e muitas outras áreas da ciência) é $\\alpha=0.05$. Este valor é normalmente interpretado como o nível de confiança mínimo que aceitamos para rejeitar a hipótese nula, e, consequentemente, concluir que a diferença nos resultados é significativa.\n",
    "\n",
    "A função ``ttest_ind_from_stats`` do módulo ``scipy.stats`` calcula a estatística t e o p-valor ($p$) a partir da média e do desvio-padrão das distribuições gaussianas que queremos comparar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd61f1f-c4b2-4a7a-b70a-efddea1175da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind_from_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d738a5-32dc-493e-9b83-3af5ebf8bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiramente calculamos a média e o desvio padrão dos resultados\n",
    "media_knn, std_knn, _, _ = calcular_estatisticas(accs_knn)\n",
    "media_svm, std_svm, _, _ = calcular_estatisticas(accs_svm)\n",
    "\n",
    "#calcular o pvalor usando o teste t de Student para duas amostras independentes\n",
    "_, pvalor = ttest_ind_from_stats(media_knn, std_knn, len(accs_knn), media_svm, std_svm, len(accs_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea0e54da-88ff-476f-bf80-5a3a9777e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866732489128373"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f869cd06-0026-404f-9212-c65879ba29eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalor<=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6dece-357c-4967-abbe-4c48e6bb82ce",
   "metadata": {},
   "source": [
    "Note que o p-valor obtido é maior que $0.05$. Portanto, não é possível rejeitar a hipótese nula. Desta forma, não há como afirmar que a diferença entre as médias dos resultados é significativa. Em outras palavras, *não é possível afirmar* que a SVM teve desempenho diferente do KNN nos testes que fizemos com esta base de dados.\n",
    "\n",
    "Podemos empacotar este teste de hipótese em uma função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b73c374a-f366-4980-8947-fa27a34ded39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejeitar_hip_nula(media_amostral1, desvio_padrao_amostral1, n1, media_amostral2, desvio_padrao_amostral2, n2, alpha=0.05):\n",
    "    _, pvalor = ttest_ind_from_stats(media_amostral1, desvio_padrao_amostral1, n1, media_amostral2, desvio_padrao_amostral2, n2)\n",
    "    return pvalor <= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5caf4d21-aa1a-4f9c-b5a5-8e66ea9ae45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejeitar_hip_nula(media_knn, std_knn, len(accs_knn), media_svm, std_svm, len(accs_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e497006-cf26-42b8-b017-ab60fe03d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
